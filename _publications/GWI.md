---
title: "Generalized Variational Inference in Function Spaces: Gaussian Measures meet Bayesian Deep Learning"
collection: publications
permalink: /publication/GWI
excerpt: 'We develop a framework for generalized variational inference in infinite-dimensional function spaces and use it to construct a method termed Gaussian Wasserstein inference (GWI)...'
date: 2022-05-12
venue: 'arxiv'
paperurl: ''
citation: 'Veit D. Wild, Robert Hu and Dino Sejdinovic (2022). &quot;Generalized Variational Inference in Function Spaces: Gaussian Measures meet Bayesian Deep Learning.&quot; <i> arXiv preprint arXiv:2205.06342. </i>'
---
We develop a framework for generalized variational inference in infinite-dimensional function spaces and use it to construct a method termed Gaussian
Wasserstein inference (GWI). GWI leverages the Wasserstein distance between
Gaussian measures on the Hilbert space of square-integrable functions in order to
determine a variational posterior using a tractable optimization criterion and avoids
pathologies arising in standard variational function space inference. An exciting
application of GWI is the ability to use deep neural networks in the variational
parametrisation of GWI, combining their superior predictive performance with
the principled uncertainty quantification analogous to that of Gaussian processes.
The proposed method obtains state-of-the-art performance on several benchmark
datasets.

[Download paper here](http://veitwild.github.io/files/GWI.pdf)